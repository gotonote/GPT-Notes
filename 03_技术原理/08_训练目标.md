# 08 训练目标

> 理解大语言模型是如何"学会"语言的——预训练任务设计详解

## 📖 为什么需要训练目标？

训练目标是告诉模型"应该学到什么"的核心指令。就像学生学习需要有考试题目一样，大语言模型需要通过特定的预训练任务来学习语言的规律。

不同的训练目标会导致模型具备不同的能力，这也是区分不同模型架构的关键。

---

## 🎯 主流训练目标

### 1. 语言建模（Language Modeling）

**下一个词预测（Next Token Prediction）**

这是 GPT 系列模型的核心训练目标：

```
输入: "今天天气很好，我们去"
输出: "公园" (预测下一个词)
```

**工作原理：**
- 给定前面的词序列，预测下一个最可能出现的词
- 训练时使用交叉熵损失函数
- 模型学习的是 P(下一个词 | 前面的词)

**数学表示：**
```
L = -Σ log P(w_t | w_1, w_2, ..., w_{t-1})
```

**特点：**
- ✅ 培养生成能力
- ✅ 适合自回归生成
- ❌ 只利用单向信息

---

### 2. 掩码语言建模（Masked Language Modeling）

**BERT 使用的训练目标**

```
原句: "今天天气很好"
掩码: "今天[MASK]很好"
预测: "天气"
```

**两种掩码策略：**

| 策略 | 说明 | 比例 |
|------|------|------|
| MLM | 随机掩码 15% 的词 | 80% 替换为 [MASK]，10% 随机词，10% 保持原词 |
| PLM | 预测整个被掩码的片段 | 较长跨度 |

**特点：**
- ✅ 利用双向上下文信息
- ✅ 适合理解任务
- ❌ 生成能力较弱

---

### 3. 序列到序列（Seq2Seq）

**T5、BART 使用的训练目标**

将输入文本转换为目标文本：

```
输入: "总结：今天天气很好，我们去公园玩。"
输出: "今天我们去公园玩了。"
```

**常见子任务：**
- 文本摘要
- 机器翻译
- 问答系统

---

## 📊 训练目标对比

| 训练目标 | 代表模型 | 适用场景 | 优势 | 劣势 |
|----------|----------|----------|------|------|
| Next Token Prediction | GPT 系列 | 文本生成 | 生成能力强 | 单向信息 |
| MLM | BERT 系列 | 理解任务 | 双向理解 | 生成弱 |
| Seq2Seq | T5, BART | 转换任务 | 任务灵活 | 计算开销大 |

---

## 🔄 训练目标的演进

### 第一代：单一目标
- ELMo：双向 LSTM + 语言模型
- GPT-1：Transformer + 语言模型

### 第二代：双向理解
- BERT：MLM + NSP（下一句预测）
- RoBERTa：改进的 MLM

### 第三代：多任务学习
- T5：统一 Seq2Seq 框架
- GPT-3：大规模 Next Token Prediction

### 第四代：指令微调
- InstructGPT：RLHF + 语言模型
- GPT-4：多模态融合

---

## 💡 训练目标对能力的影响

| 能力 | Next Token Prediction | MLM | Seq2Seq |
|------|------------------------|-----|---------|
| 文本生成 | ⭐⭐⭐ | ⭐ | ⭐⭐ |
| 阅读理解 | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |
| 问答系统 | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| 机器翻译 | ⭐ | ⭐ | ⭐⭐⭐ |
| 代码生成 | ⭐⭐⭐ | ⭐ | ⭐⭐ |

---

## 🧠 训练目标的数学理解

### 自回归建模

```
P(文本) = P(w_1) × P(w_2|w_1) × P(w_3|w_1,w_2) × ... × P(w_n|w_1,...,w_{n-1})
```

模型通过最大化这个联合概率来学习。

### 交叉熵损失

```
L = -Σ_{i=1}^{N} log P(w_i | w_1, ..., w_{i-1}; θ)
```

其中 θ 是模型参数，通过梯度下降优化。

---

## 🔑 核心要点总结

1. **训练目标决定模型能力** - 不同的预训练任务会赋予模型不同的能力
2. **Next Token Prediction** - GPT 系列的核心，适合生成任务
3. **MLM** - BERT 系列的核心，适合理解任务
4. **训练目标可以组合** - 现代模型往往结合多种训练目标
5. **规模很重要** - 同样的训练目标，更大的数据和模型通常带来更好的效果

---

## 📅 更新日志

| 日期 | 内容 |
|------|------|
| 2026-02-25 | 新增训练目标详解 |
