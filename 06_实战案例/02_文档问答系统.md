# æ¡ˆä¾‹äºŒï¼šæ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆRAG å®æˆ˜ï¼‰

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªåŸºäº **RAG (Retrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆ)** æŠ€æœ¯çš„æ–‡æ¡£é—®ç­”ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿè®©ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ï¼Œç„¶ååŸºäºæ–‡æ¡£å†…å®¹è¿›è¡Œæ™ºèƒ½é—®ç­”ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ–‡æ¡£é—®ç­”ç³»ç»Ÿæ¶æ„å›¾                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ æ–‡æ¡£ä¸Šä¼  â”‚ â”€â”€â”€â–¶ â”‚ æ–‡æœ¬åˆ†å‰²    â”‚ â”€â”€â”€â–¶ â”‚ Embedding ç¼–ç   â”‚   â”‚
â”‚   â”‚ (PDF/TXT)â”‚      â”‚ (Chunking)  â”‚      â”‚ (å‘é‡åŒ–)        â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                    â”‚            â”‚
â”‚                                                    â–¼            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚              å‘é‡æ•°æ®åº“ (Vector DB)                   â”‚    â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚   â”‚   â”‚  Doc1_Chunk1  â”€â”€â–¶  [0.23, -0.45, 0.89, ...] â”‚   â”‚    â”‚
â”‚   â”‚   â”‚  Doc1_Chunk2  â”€â”€â–¶  [-0.12, 0.67, -0.34, ...]â”‚   â”‚    â”‚
â”‚   â”‚   â”‚  Doc2_Chunk1  â”€â”€â–¶  [0.56, -0.23, 0.78, ...] â”‚   â”‚    â”‚
â”‚   â”‚   â”‚  ...                                         â”‚   â”‚    â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                   â”‚
â”‚                            â”‚ ç›¸ä¼¼åº¦æ£€ç´¢                         â”‚
â”‚                            â–¼                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ ç”¨æˆ·æé—® â”‚ â”€â”€â”€â–¶ â”‚ æŸ¥è¯¢å‘é‡åŒ–  â”‚ â”€â”€â”€â–¶ â”‚ Top-K ç›¸ä¼¼æ£€ç´¢  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                    â”‚            â”‚
â”‚                                                    â–¼            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚                    å¤§æ¨¡å‹ (LLM)                       â”‚    â”‚
â”‚   â”‚  è¾“å…¥: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æœ¬ + ç”¨æˆ·é—®é¢˜                     â”‚    â”‚
â”‚   â”‚  è¾“å‡º: åŸºäºæ–‡æ¡£å†…å®¹çš„å‡†ç¡®å›ç­”                          â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ RAG å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant API as API æœåŠ¡
    participant Embed as Embedding æœåŠ¡
    participant VDB as å‘é‡æ•°æ®åº“
    participant LLM as å¤§æ¨¡å‹

    %% æ–‡æ¡£å¤„ç†æµç¨‹
    rect rgb(230, 245, 255)
        Note over U,LLM: ğŸ“„ æ–‡æ¡£å¤„ç†é˜¶æ®µ
        U->>API: ä¸Šä¼ æ–‡æ¡£ (PDF/DOCX)
        API->>API: 1. è§£ææ–‡æ¡£å†…å®¹
        API->>API: 2. æ–‡æœ¬åˆ†å‰² (Chunking)
        loop æ¯ä¸ªæ–‡æœ¬å—
            API->>Embed: 3. ç”Ÿæˆå‘é‡åµŒå…¥
            Embed-->>API: è¿”å›å‘é‡
            API->>VDB: 4. å­˜å‚¨å‘é‡+åŸæ–‡
        end
        VDB-->>API: å­˜å‚¨å®Œæˆ
        API-->>U: æ–‡æ¡£å¤„ç†æˆåŠŸ
    end

    %% é—®ç­”æµç¨‹
    rect rgb(255, 245, 230)
        Note over U,LLM: â“ é—®ç­”é˜¶æ®µ
        U->>API: æå‡ºé—®é¢˜
        API->>Embed: 1. é—®é¢˜å‘é‡åŒ–
        Embed-->>API: è¿”å›æŸ¥è¯¢å‘é‡
        API->>VDB: 2. ç›¸ä¼¼åº¦æœç´¢ (Top-K)
        VDB-->>API: è¿”å›ç›¸å…³æ–‡æœ¬å—
        API->>API: 3. æ„å»º Prompt
        API->>LLM: 4. è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ
        LLM-->>API: è¿”å›å›ç­”
        API->>API: 5. åå¤„ç†+æº¯æº
        API-->>U: è¿”å›ç­”æ¡ˆ+å¼•ç”¨
    end
```

## ğŸ’» æ ¸å¿ƒä»£ç å®ç°

```python
"""
RAG æ–‡æ¡£é—®ç­”ç³»ç»Ÿ
åŸºäº LangChain æ¡†æ¶å®ç°

ä¾èµ–å®‰è£…:
pip install langchain langchain-openai chromadb pypdf unstructured
"""

import os
import tempfile
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

from langchain.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredWordDocumentLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document


# ==================== é…ç½® ====================

class RAGConfig:
    """RAG ç³»ç»Ÿé…ç½®"""
    # API é…ç½®
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # æ–‡æœ¬åˆ†å‰²å‚æ•°
    CHUNK_SIZE = 500        # æ¯ä¸ªæ–‡æœ¬å—çš„å¤§å°
    CHUNK_OVERLAP = 50      # é‡å å¤§å°ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯
    
    # æ£€ç´¢å‚æ•°
    TOP_K = 5               # æ£€ç´¢æœ€ç›¸å…³çš„ K ä¸ªæ–‡æœ¬å—
    SIMILARITY_THRESHOLD = 0.7  # ç›¸ä¼¼åº¦é˜ˆå€¼
    
    # æ¨¡å‹é…ç½®
    LLM_MODEL = "gpt-3.5-turbo"
    TEMPERATURE = 0.0       # 0 è¡¨ç¤ºæ›´ç¡®å®šçš„å›ç­”


# ==================== æ–‡æ¡£å¤„ç†å™¨ ====================

class DocumentProcessor:
    """
    æ–‡æ¡£å¤„ç†ç±»
    è´Ÿè´£åŠ è½½ã€è§£æå’Œåˆ†å‰²æ–‡æ¡£
    """
    
    # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
    SUPPORTED_EXTENSIONS = {
        '.pdf': PyPDFLoader,
        '.txt': TextLoader,
        '.docx': UnstructuredWordDocumentLoader,
        '.doc': UnstructuredWordDocumentLoader
    }
    
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=RAGConfig.CHUNK_SIZE,
            chunk_overlap=RAGConfig.CHUNK_OVERLAP,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼›", " ", ""]
        )
    
    def load_document(self, file_path: str) -> List[Document]:
        """
        åŠ è½½æ–‡æ¡£
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
        
        Returns:
            Document å¯¹è±¡åˆ—è¡¨
        """
        path = Path(file_path)
        extension = path.suffix.lower()
        
        if extension not in self.SUPPORTED_EXTENSIONS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {extension}")
        
        loader_class = self.SUPPORTED_EXTENSIONS[extension]
        loader = loader_class(file_path)
        
        print(f"ğŸ“„ æ­£åœ¨åŠ è½½æ–‡æ¡£: {path.name}")
        documents = loader.load()
        print(f"   âœ“ åŠ è½½å®Œæˆï¼Œå…± {len(documents)} é¡µ/æ®µ")
        
        return documents
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """
        åˆ†å‰²æ–‡æ¡£ä¸ºæ–‡æœ¬å—
        
        Args:
            documents: åŸå§‹æ–‡æ¡£åˆ—è¡¨
        
        Returns:
            åˆ†å‰²åçš„æ–‡æœ¬å—åˆ—è¡¨
        """
        print(f"âœ‚ï¸  æ­£åœ¨åˆ†å‰²æ–‡æ¡£...")
        chunks = self.text_splitter.split_documents(documents)
        print(f"   âœ“ åˆ†å‰²å®Œæˆï¼Œå…± {len(chunks)} ä¸ªæ–‡æœ¬å—")
        print(f"   âœ“ å¹³å‡å—å¤§å°: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} å­—ç¬¦")
        
        return chunks
    
    def process(self, file_path: str) -> List[Document]:
        """
        å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
        
        Returns:
            å¤„ç†åçš„æ–‡æœ¬å—
        """
        documents = self.load_document(file_path)
        chunks = self.split_documents(documents)
        
        # æ·»åŠ å…ƒæ•°æ®
        for i, chunk in enumerate(chunks):
            chunk.metadata.update({
                "chunk_index": i,
                "source_file": Path(file_path).name,
                "total_chunks": len(chunks)
            })
        
        return chunks


# ==================== å‘é‡å­˜å‚¨ç®¡ç†å™¨ ====================

class VectorStoreManager:
    """
    å‘é‡å­˜å‚¨ç®¡ç†ç±»
    è´Ÿè´£å‘é‡çš„å­˜å‚¨ã€æ£€ç´¢å’Œç®¡ç†
    """
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨
        
        Args:
            persist_directory: æŒä¹…åŒ–ç›®å½•
        """
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=RAGConfig.OPENAI_API_KEY
        )
        self.vectorstore = None
        
        # å¦‚æœå­˜åœ¨å·²æœ‰æ•°æ®åº“ï¼ŒåŠ è½½å®ƒ
        if os.path.exists(persist_directory):
            print(f"ğŸ“¦ åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“: {persist_directory}")
            self.vectorstore = Chroma(
                persist_directory=persist_directory,
                embedding_function=self.embeddings
            )
    
    def add_documents(self, documents: List[Document], collection_name: str = "default"):
        """
        æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            documents: è¦æ·»åŠ çš„æ–‡æœ¬å—
            collection_name: é›†åˆåç§°
        """
        print(f"ğŸ”¢ æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...")
        
        if self.vectorstore is None:
            # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
            self.vectorstore = Chroma.from_documents(
                documents=documents,
                embedding=self.embeddings,
                persist_directory=self.persist_directory,
                collection_name=collection_name
            )
        else:
            # æ·»åŠ åˆ°ç°æœ‰å­˜å‚¨
            self.vectorstore.add_documents(documents)
        
        # æŒä¹…åŒ–
        self.vectorstore.persist()
        print(f"   âœ“ å‘é‡å­˜å‚¨å®Œæˆï¼Œå·²æŒä¹…åŒ–åˆ°: {self.persist_directory}")
    
    def similarity_search(
        self,
        query: str,
        k: int = None,
        filter_dict: Dict = None
    ) -> List[Tuple[Document, float]]:
        """
        ç›¸ä¼¼åº¦æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›ç»“æœæ•°é‡
            filter_dict: è¿‡æ»¤æ¡ä»¶
        
        Returns:
            (æ–‡æ¡£, ç›¸ä¼¼åº¦åˆ†æ•°) åˆ—è¡¨
        """
        if self.vectorstore is None:
            raise ValueError("å‘é‡æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ æ–‡æ¡£")
        
        k = k or RAGConfig.TOP_K
        
        # ä½¿ç”¨ similarity_search_with_score è·å–ç›¸ä¼¼åº¦åˆ†æ•°
        results = self.vectorstore.similarity_search_with_score(
            query=query,
            k=k,
            filter=filter_dict
        )
        
        return results
    
    def get_retriever(self, search_kwargs: Dict = None):
        """
        è·å–æ£€ç´¢å™¨ï¼Œç”¨äº QA Chain
        """
        if self.vectorstore is None:
            raise ValueError("å‘é‡æ•°æ®åº“ä¸ºç©º")
        
        search_kwargs = search_kwargs or {"k": RAGConfig.TOP_K}
        return self.vectorstore.as_retriever(search_kwargs=search_kwargs)


# ==================== é—®ç­”å¼•æ“ ====================

class QAEngine:
    """
    é—®ç­”å¼•æ“
    æ ¸å¿ƒåŠŸèƒ½ï¼šåŸºäºæ£€ç´¢çš„é—®ç­”
    """
    
    # è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
    QA_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ã€å›ç­”è§„åˆ™ã€‘
1. åªåŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦æ·»åŠ å¤–éƒ¨çŸ¥è¯†
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥"æ ¹æ®æä¾›çš„æ–‡æ¡£ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. ä¿æŒå›ç­”ç®€æ´å‡†ç¡®ï¼Œé¿å…å†—é•¿
4. å¦‚æœ‰å¤šä¸ªç›¸å…³ä¿¡æ¯ï¼Œè¯·ç»¼åˆæ•´ç†

ã€ç›¸å…³æ–‡æ¡£å†…å®¹ã€‘
{context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

è¯·åŸºäºä»¥ä¸Šæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š"""
    
    def __init__(self, vector_store_manager: VectorStoreManager):
        """
        åˆå§‹åŒ–é—®ç­”å¼•æ“
        
        Args:
            vector_store_manager: å‘é‡å­˜å‚¨ç®¡ç†å™¨
        """
        self.vector_store = vector_store_manager
        
        # åˆå§‹åŒ–å¤§æ¨¡å‹
        self.llm = ChatOpenAI(
            model_name=RAGConfig.LLM_MODEL,
            temperature=RAGConfig.TEMPERATURE,
            openai_api_key=RAGConfig.OPENAI_API_KEY
        )
        
        # åˆ›å»ºæç¤ºè¯
        self.qa_prompt = PromptTemplate(
            template=self.QA_PROMPT_TEMPLATE,
            input_variables=["context", "question"]
        )
        
        # æ„å»º QA Chain
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",  # ç®€å•åœ°å°†æ‰€æœ‰æ–‡æ¡£æ‹¼æ¥
            retriever=self.vector_store.get_retriever(),
            return_source_documents=True,
            chain_type_kwargs={"prompt": self.qa_prompt}
        )
    
    def ask(self, question: str) -> Dict:
        """
        æå‡ºé—®é¢˜å¹¶è·å–ç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œæºæ–‡æ¡£çš„å­—å…¸
        """
        print(f"\nâ“ ç”¨æˆ·é—®é¢˜: {question}")
        print("-" * 50)
        
        # é¦–å…ˆæ‰§è¡Œç›¸ä¼¼åº¦æœç´¢ï¼ŒæŸ¥çœ‹æ£€ç´¢ç»“æœ
        search_results = self.vector_store.similarity_search(question)
        print(f"ğŸ” æ£€ç´¢åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æœ¬å—")
        
        for i, (doc, score) in enumerate(search_results, 1):
            print(f"   [{i}] ç›¸ä¼¼åº¦: {1-score:.3f} | æ¥æº: {doc.metadata.get('source_file', 'N/A')}")
        
        # æ‰§è¡Œé—®ç­”
        result = self.qa_chain({"query": question})
        
        return {
            "question": question,
            "answer": result["result"],
            "source_documents": result["source_documents"]
        }
    
    def ask_with_sources(self, question: str) -> str:
        """
        æé—®å¹¶è¿”å›æ ¼å¼åŒ–çš„ç­”æ¡ˆï¼ˆåŒ…å«å¼•ç”¨ï¼‰
        """
        result = self.ask(question)
        
        # æ„å»ºå¸¦å¼•ç”¨çš„å›ç­”
        answer = result["answer"]
        sources = result["source_documents"]
        
        # æ·»åŠ å¼•ç”¨ä¿¡æ¯
        source_info = "\n\nğŸ“š å‚è€ƒæ¥æº:\n"
        seen_files = set()
        for i, doc in enumerate(sources, 1):
            file_name = doc.metadata.get('source_file', 'Unknown')
            if file_name not in seen_files:
                source_info += f"   [{i}] {file_name}\n"
                seen_files.add(file_name)
        
        return answer + source_info


# ==================== å®Œæ•´ç³»ç»Ÿå°è£… ====================

class DocumentQASystem:
    """
    æ–‡æ¡£é—®ç­”ç³»ç»Ÿä¸»ç±»
    æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›ç®€æ´çš„æ¥å£
    """
    
    def __init__(self, db_path: str = "./qa_vector_db"):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            db_path: å‘é‡æ•°æ®åº“è·¯å¾„
        """
        self.doc_processor = DocumentProcessor()
        self.vector_store = VectorStoreManager(db_path)
        self.qa_engine = None
        
        # å¦‚æœå·²æœ‰æ•°æ®ï¼Œåˆå§‹åŒ– QA å¼•æ“
        if self.vector_store.vectorstore is not None:
            self.qa_engine = QAEngine(self.vector_store)
    
    def upload_document(self, file_path: str) -> bool:
        """
        ä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. å¤„ç†æ–‡æ¡£
            chunks = self.doc_processor.process(file_path)
            
            # 2. æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            self.vector_store.add_documents(chunks)
            
            # 3. é‡æ–°åˆå§‹åŒ– QA å¼•æ“
            self.qa_engine = QAEngine(self.vector_store)
            
            print(f"âœ… æ–‡æ¡£ '{Path(file_path).name}' å¤„ç†å®Œæˆï¼")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return False
    
    def query(self, question: str) -> str:
        """
        æŸ¥è¯¢é—®é¢˜
        
        Args:
            question: é—®é¢˜
        
        Returns:
            å›ç­”
        """
        if self.qa_engine is None:
            return "ç³»ç»Ÿå°šæœªåŠ è½½ä»»ä½•æ–‡æ¡£ï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£ã€‚"
        
        return self.qa_engine.ask_with_sources(question)
    
    def get_stats(self) -> Dict:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "has_documents": self.vector_store.vectorstore is not None,
            "db_path": self.vector_store.persist_directory
        }
        
        if self.vector_store.vectorstore:
            # è·å–é›†åˆä¿¡æ¯
            try:
                stats["document_count"] = self.vector_store.vectorstore._collection.count()
            except:
                stats["document_count"] = "Unknown"
        
        return stats


# ==================== æ¼”ç¤º ====================

def create_sample_document():
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ç”¨äºæµ‹è¯•"""
    sample_text = """
# å…¬å¸å¹´åº¦è´¢æŠ¥ 2024

## ä¸€ã€å…¬å¸æ¦‚å†µ

ç§‘æŠ€åˆ›æ–°æœ‰é™å…¬å¸æˆç«‹äº2018å¹´ï¼Œä¸“æ³¨äºäººå·¥æ™ºèƒ½å’Œä¼ä¸šè½¯ä»¶è§£å†³æ–¹æ¡ˆã€‚
å…¬å¸æ€»éƒ¨ä½äºåŒ—äº¬ï¼Œåœ¨ä¸Šæµ·ã€æ·±åœ³è®¾æœ‰åˆ†å…¬å¸ã€‚

## äºŒã€è´¢åŠ¡æ•°æ®

2024å¹´åº¦ä¸»è¦è´¢åŠ¡æŒ‡æ ‡ï¼š
- è¥ä¸šæ”¶å…¥ï¼š12.5äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿35%
- å‡€åˆ©æ¶¦ï¼š2.8äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿42%
- ç ”å‘æŠ•å…¥ï¼š3.2äº¿å…ƒï¼Œå è¥æ”¶25.6%
- å‘˜å·¥äººæ•°ï¼š1,250äºº

## ä¸‰ã€æ ¸å¿ƒä¸šåŠ¡

### 3.1 äººå·¥æ™ºèƒ½å¹³å°
æˆ‘ä»¬çš„AIå¹³å°æœåŠ¡äºè¶…è¿‡500å®¶ä¼ä¸šå®¢æˆ·ï¼Œæä¾›ï¼š
- è‡ªç„¶è¯­è¨€å¤„ç†æœåŠ¡
- è®¡ç®—æœºè§†è§‰è§£å†³æ–¹æ¡ˆ
- æ™ºèƒ½æ•°æ®åˆ†æ

### 3.2 ä¼ä¸šè½¯ä»¶
ä¼ä¸šè½¯ä»¶ä¸šåŠ¡çº¿æ”¶å…¥å æ¯”40%ï¼Œä¸»è¦äº§å“åŒ…æ‹¬ï¼š
- ä¼ä¸šèµ„æºè®¡åˆ’ç³»ç»Ÿ (ERP)
- å®¢æˆ·å…³ç³»ç®¡ç†ç³»ç»Ÿ (CRM)
- äººåŠ›èµ„æºç®¡ç†ç³»ç»Ÿ (HRM)

## å››ã€æœªæ¥å±•æœ›

2025å¹´æˆ˜ç•¥ç›®æ ‡ï¼š
1. è¥æ”¶çªç ´20äº¿å…ƒ
2. æ‹“å±•æµ·å¤–å¸‚åœº
3. æ¨å‡ºæ–°ä¸€ä»£å¤§æ¨¡å‹äº§å“
4. å‘˜å·¥è§„æ¨¡æ‰©å¤§åˆ°2,000äºº

## äº”ã€è”ç³»æ–¹å¼

- æŠ•èµ„è€…å…³ç³»ï¼šir@tech-innovation.com
- å®¢æœçƒ­çº¿ï¼š400-888-9999
- å…¬å¸å®˜ç½‘ï¼šwww.tech-innovation.com
"""
    
    # å†™å…¥ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        f.write(sample_text)
        return f.name


def demo():
    """æ¼”ç¤ºæ–‡æ¡£é—®ç­”ç³»ç»Ÿ"""
    
    print("=" * 60)
    print("ğŸ“š RAG æ–‡æ¡£é—®ç­”ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    qa_system = DocumentQASystem(db_path="./demo_vector_db")
    
    # åˆ›å»ºå¹¶ä¸Šä¼ ç¤ºä¾‹æ–‡æ¡£
    print("\nğŸ“„ åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...")
    sample_file = create_sample_document()
    qa_system.upload_document(sample_file)
    
    # æŸ¥è¯¢é—®é¢˜
    questions = [
        "è¿™å®¶å…¬å¸çš„è¥ä¸šæ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ",
        "å…¬å¸æ€»éƒ¨åœ¨å“ªé‡Œï¼Ÿ",
        "ä¸»è¦ä¸šåŠ¡æœ‰å“ªäº›ï¼Ÿ",
        "2025å¹´çš„æˆ˜ç•¥ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¿™å®¶å…¬å¸çš„åˆ›å§‹äººæ˜¯è°ï¼Ÿ"  # æ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯
    ]
    
    print("\n" + "=" * 60)
    print("ğŸ¤– å¼€å§‹é—®ç­”")
    print("=" * 60)
    
    for q in questions:
        print("\n" + "-" * 60)
        answer = qa_system.query(q)
        print(f"\nğŸ’¡ å›ç­”:\n{answer}")
    
    # æ¸…ç†
    os.unlink(sample_file)
    print(f"\n\nâœ… æ¼”ç¤ºå®Œæˆï¼å‘é‡æ•°æ®åº“ä¿å­˜åœ¨: ./demo_vector_db")


if __name__ == "__main__":
    demo()
```

## ğŸ“Š RAG vs å¾®è°ƒå¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 RAG vs Fine-tuning é€‰æ‹©æŒ‡å—                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ã€ä½¿ç”¨ RAG çš„æƒ…å†µã€‘              ã€ä½¿ç”¨å¾®è°ƒçš„æƒ…å†µã€‘             â”‚
â”‚                                                                 â”‚
â”‚   âœ… éœ€è¦å¼•ç”¨ä¿¡æ¯æ¥æº              âœ… éœ€è¦æ”¹å˜æ¨¡å‹è¡Œä¸º/è¯­æ°”        â”‚
â”‚   âœ… æ•°æ®ç»å¸¸æ›´æ–°                  âœ… æ‰§è¡Œç‰¹å®šæ ¼å¼çš„ä»»åŠ¡          â”‚
â”‚   âœ… æ•°æ®é‡å¾ˆå¤§                    âœ… æ•°æ®é‡ç›¸å¯¹è¾ƒå°              â”‚
â”‚   âœ… éœ€è¦é™ä½æˆæœ¬                  âœ… éœ€è¦å‡å°‘å»¶è¿Ÿ               â”‚
â”‚   âœ… ä¿æŠ¤æ•°æ®éšç§ï¼ˆä¸å‘é€ç»™LLMï¼‰    âœ… æ•°æ®å¯¹å…¬ä¼—æ•æ„Ÿ             â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ã€RAG çš„ä¼˜åŠ¿ã€‘                                                â”‚
â”‚   â€¢ åŠ¨æ€æ›´æ–°çŸ¥è¯† - æ— éœ€é‡æ–°è®­ç»ƒ                                  â”‚
â”‚   â€¢ å¯è¿½æº¯ - èƒ½æ˜¾ç¤ºä¿¡æ¯æ¥æº                                      â”‚
â”‚   â€¢ æˆæœ¬è¾ƒä½ - æ— éœ€è®­ç»ƒè´¹ç”¨                                      â”‚
â”‚   â€¢ æ›´å®‰å…¨ - æ•°æ®å­˜å‚¨åœ¨æœ¬åœ°                                      â”‚
â”‚                                                                 â”‚
â”‚   ã€å¾®è°ƒçš„ä¼˜åŠ¿ã€‘                                                â”‚
â”‚   â€¢ æ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒ                                            â”‚
â”‚   â€¢ æ¨ç†é€Ÿåº¦æ›´å¿«                                                â”‚
â”‚   â€¢ å¯åœ¨ç¦»çº¿ç¯å¢ƒè¿è¡Œ                                            â”‚
â”‚   â€¢ é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„ä¼˜åŒ–                                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ å…³é”®æŠ€æœ¯ç‚¹

### 1. æ–‡æœ¬åˆ†å‰²ç­–ç•¥

```python
# ä¸åŒåˆ†å‰²ç­–ç•¥å¯¹æ¯”
def chunking_strategies():
    """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ç­–ç•¥ç±»å‹        é€‚ç”¨åœºæ™¯            ä¼˜ç¼ºç‚¹               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  å›ºå®šé•¿åº¦        é€šç”¨åœºæ™¯            ç®€å•ä½†å¯èƒ½åˆ‡æ–­è¯­ä¹‰   â”‚
    â”‚  é€’å½’åˆ†å‰²        ç»“æ„åŒ–æ–‡æ¡£          ä¿ç•™æ®µè½ç»“æ„         â”‚
    â”‚  è¯­ä¹‰åˆ†å‰²        é•¿æ–‡æ¡£              æŒ‰ä¸»é¢˜åˆ‡åˆ†ï¼Œç²¾åº¦é«˜   â”‚
    â”‚  Agentic         å¤æ‚æ–‡æ¡£            æ™ºèƒ½å†³ç­–ï¼Œæˆæœ¬é«˜     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    pass
```

### 2. æ£€ç´¢ä¼˜åŒ–æŠ€å·§

| æŠ€å·§ | è¯´æ˜ | æ•ˆæœ |
|------|------|------|
| **Query æ‰©å±•** | ç”¨ LLM æ‰©å±•ç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆå¤šä¸ªå˜ä½“ | æé«˜å¬å›ç‡ |
| **é‡æ’åº (Rerank)** | ä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å‹å¯¹åˆæ­¥ç»“æœé‡æ’åº | æé«˜ç²¾åº¦ |
| **æ··åˆæ£€ç´¢** | å‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢ç»“åˆ | å¹³è¡¡ç²¾åº¦å’Œå¬å› |
| **HyDE** | ç”¨ LLM ç”Ÿæˆå‡è®¾æ–‡æ¡£å†æ£€ç´¢ | å¤„ç†å¤æ‚æŸ¥è¯¢ |

### 3. å¸¸è§å‘é‡æ•°æ®åº“å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å‘é‡æ•°æ®åº“å¯¹æ¯”                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    æ•°æ®åº“    â”‚ å¼€æº     â”‚ æ‰˜ç®¡     â”‚ æ€§èƒ½     â”‚ é€‚åˆåœºæ™¯      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chroma      â”‚    âœ“     â”‚    âœ—     â”‚  ä¸­      â”‚ å¼€å‘/åŸå‹     â”‚
â”‚  Milvus      â”‚    âœ“     â”‚    âœ“     â”‚  é«˜      â”‚ ç”Ÿäº§ç¯å¢ƒ      â”‚
â”‚  Pinecone    â”‚    âœ—     â”‚    âœ“     â”‚  é«˜      â”‚ å¿«é€Ÿä¸Šæ‰‹      â”‚
â”‚  Weaviate    â”‚    âœ“     â”‚    âœ“     â”‚  é«˜      â”‚ ä¼ä¸šåº”ç”¨      â”‚
â”‚  Qdrant      â”‚    âœ“     â”‚    âœ“     â”‚  ä¸­é«˜    â”‚ äº‘æœåŠ¡        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ è¿›é˜¶ï¼šå¤šæ–‡æ¡£é—®ç­”

```python
class MultiDocumentQA:
    """æ”¯æŒå¤šä¸ªæ–‡æ¡£é›†åˆçš„é—®ç­”ç³»ç»Ÿ"""
    
    def __init__(self):
        self.collections = {}  # ä¸åŒç±»åˆ«çš„æ–‡æ¡£é›†åˆ
    
    def add_collection(self, name: str, documents: List[str]):
        """æ·»åŠ æ–‡æ¡£é›†åˆ"""
        self.collections[name] = {
            'documents': documents,
            'vectorstore': self._create_vectorstore(documents)
        }
    
    def query(self, question: str, collection: str = None) -> Dict:
        """
        æŸ¥è¯¢ï¼Œå¯æŒ‡å®šç‰¹å®šé›†åˆæˆ–è·¨é›†åˆæŸ¥è¯¢
        
        æµç¨‹:
        1. å…ˆè¯†åˆ«é—®é¢˜æ¶‰åŠå“ªä¸ªæ–‡æ¡£é›†åˆ
        2. åœ¨å¯¹åº”é›†åˆä¸­æ£€ç´¢
        3. å¦‚æœæ²¡æœ‰æŒ‡å®šé›†åˆï¼Œè·¨æ‰€æœ‰é›†åˆæ£€ç´¢
        """
        if collection and collection in self.collections:
            # ç‰¹å®šé›†åˆæŸ¥è¯¢
            return self._query_collection(question, collection)
        else:
            # è·¯ç”±åˆ°æœ€åˆé€‚çš„é›†åˆ
            target = self._route_question(question)
            return self._query_collection(question, target)
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
- [Vector Databases: A Technical Overview](https://www.pinecone.io/learn/vector-database/)

---

*æœ€åæ›´æ–°: 2025å¹´2æœˆ14æ—¥*
