# å¤§æ¨¡å‹å®æˆ˜æ¡ˆä¾‹

æœ¬ç« èŠ‚é€šè¿‡å®é™…æ¡ˆä¾‹ï¼Œå¸®åŠ©åˆå­¦è€…å°†å¤§æ¨¡å‹æŠ€æœ¯åº”ç”¨åˆ°çœŸå®åœºæ™¯ä¸­ã€‚ç”±æµ…å…¥æ·±ï¼Œæ¶µç›–ä»ç®€å•çš„ API è°ƒç”¨åˆ°å¤æ‚çš„åº”ç”¨å¼€å‘ã€‚

---

## ç›®å½•

1. [æ¡ˆä¾‹ä¸€ï¼šæ™ºèƒ½å®¢æœèŠå¤©æœºå™¨äºº](#æ¡ˆä¾‹ä¸€æ™ºèƒ½å®¢æœèŠå¤©æœºå™¨äºº)
2. [æ¡ˆä¾‹äºŒï¼šæ–‡æ¡£é—®ç­”ç³»ç»Ÿ](#æ¡ˆä¾‹äºŒæ–‡æ¡£é—®ç­”ç³»ç»Ÿ)
3. [æ¡ˆä¾‹ä¸‰ï¼šä»£ç è¾…åŠ©å·¥å…·](#æ¡ˆä¾‹ä¸‰ä»£ç è¾…åŠ©å·¥å…·)
4. [æ¡ˆä¾‹å››ï¼šæ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹](#æ¡ˆä¾‹å››æ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹)
5. [æ¡ˆä¾‹äº”ï¼šå¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿ](#æ¡ˆä¾‹äº”å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿ)

---

## æ¡ˆä¾‹ä¸€ï¼šæ™ºèƒ½å®¢æœèŠå¤©æœºå™¨äºº

### ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªåŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·å…³äºäº§å“çš„å¸¸è§é—®é¢˜ï¼Œå¹¶åœ¨éœ€è¦æ—¶è½¬æ¥äººå·¥å®¢æœã€‚

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ç”¨æˆ·ç•Œé¢                             â”‚
â”‚                   (Web / APP / å°ç¨‹åº)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API ç½‘å…³å±‚                              â”‚
â”‚              (é‰´æƒã€é™æµã€è¯·æ±‚è½¬å‘)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å±‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ„å›¾è¯†åˆ«    â”‚  â”‚ ä¸Šä¸‹æ–‡ç®¡ç†  â”‚  â”‚ çŸ¥è¯†åº“æ£€ç´¢          â”‚  â”‚
â”‚  â”‚ (Intent)    â”‚  â”‚ (Context)   â”‚  â”‚ (RAG)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                           â–¼                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚  æç¤ºè¯å·¥ç¨‹  â”‚                         â”‚
â”‚                    â”‚  (Prompt)   â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              å¤§æ¨¡å‹æœåŠ¡ (LLM API)                    â”‚   â”‚
â”‚  â”‚         GPT-4 / Claude / æ–‡å¿ƒä¸€è¨€ ç­‰                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®æŒä¹…åŒ–å±‚                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚     â”‚å¯¹è¯è®°å½•  â”‚  â”‚ç”¨æˆ·ç”»åƒ  â”‚  â”‚çŸ¥è¯†åº“å‘é‡æ•°æ®åº“  â”‚       â”‚
â”‚     â”‚(MySQL)   â”‚  â”‚(Redis)   â”‚  â”‚(Milvus/Pinecone) â”‚       â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ å¯¹è¯æµç¨‹å›¾

```mermaid
flowchart TD
    A[ç”¨æˆ·è¾“å…¥é—®é¢˜] --> B{æ„å›¾è¯†åˆ«}
    B -->|å’¨è¯¢äº§å“| C[æ£€ç´¢äº§å“çŸ¥è¯†åº“]
    B -->|å”®åæœåŠ¡| D[æ£€ç´¢å”®åæ”¿ç­–]
    B -->|æŠ•è¯‰å»ºè®®| E[è½¬æ¥äººå·¥å®¢æœ]
    B -->|é—²èŠ| F[å‹å¥½å›å¤]
    
    C --> G{ç½®ä¿¡åº¦>0.8?}
    D --> G
    
    G -->|æ˜¯| H[ç”Ÿæˆä¸“ä¸šå›ç­”]
    G -->|å¦| I[è¿½é—®æ¾„æ¸…]
    I --> J[é‡æ–°ç†è§£æ„å›¾]
    J --> B
    
    H --> K[è®°å½•å¯¹è¯ä¸Šä¸‹æ–‡]
    F --> K
    E --> L[äººå·¥ä»‹å…¥]
    
    K --> M[è¿”å›ç»™ç”¨æˆ·]
    L --> M
```

### ğŸ’» æ ¸å¿ƒä»£ç å®ç°

```python
"""
æ™ºèƒ½å®¢æœèŠå¤©æœºå™¨äººå®ç°
ä½œè€…: GPT-Notes
ç‰ˆæœ¬: 1.0.0
"""

import os
import json
import time
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import openai
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ==================== é…ç½®éƒ¨åˆ† ====================

class Config:
    """ç³»ç»Ÿé…ç½®ç±»"""
    # OpenAI API é…ç½®
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key")
    MODEL_NAME = "gpt-3.5-turbo"  # å¯æ ¹æ®éœ€è¦åˆ‡æ¢æ¨¡å‹
    MAX_TOKENS = 1000
    TEMPERATURE = 0.7
    
    # æ„å›¾è¯†åˆ«é˜ˆå€¼
    CONFIDENCE_THRESHOLD = 0.8
    
    # ä¸Šä¸‹æ–‡ç®¡ç†
    MAX_CONTEXT_LENGTH = 10  # ä¿å­˜æœ€è¿‘10è½®å¯¹è¯


# ==================== æ•°æ®æ¨¡å‹ ====================

class IntentType(Enum):
    """æ„å›¾ç±»å‹æšä¸¾"""
    PRODUCT_INQUIRY = "product_inquiry"      # äº§å“å’¨è¯¢
    AFTER_SALES = "after_sales"              # å”®åæœåŠ¡
    COMPLAINT = "complaint"                  # æŠ•è¯‰å»ºè®®
    SMALL_TALK = "small_talk"                # é—²èŠ
    UNKNOWN = "unknown"                      # æœªçŸ¥æ„å›¾


@dataclass
class Message:
    """æ¶ˆæ¯æ•°æ®ç±»"""
    role: str  # 'user' æˆ– 'assistant'
    content: str
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œç”¨äº API è°ƒç”¨"""
        return {
            "role": self.role,
            "content": self.content
        }


@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†"""
    session_id: str
    messages: List[Message]
    user_profile: Dict
    
    def add_message(self, role: str, content: str):
        """æ·»åŠ æ–°æ¶ˆæ¯ï¼Œä¿æŒä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶"""
        self.messages.append(Message(role=role, content=content))
        # åªä¿ç•™æœ€è¿‘çš„å¯¹è¯
        if len(self.messages) > Config.MAX_CONTEXT_LENGTH * 2:
            self.messages = self.messages[-Config.MAX_CONTEXT_LENGTH * 2:]
    
    def get_messages_for_api(self) -> List[Dict]:
        """è·å– API è°ƒç”¨çš„æ¶ˆæ¯æ ¼å¼"""
        return [msg.to_dict() for msg in self.messages]


# ==================== çŸ¥è¯†åº“å®ç° ====================

class KnowledgeBase:
    """
    ç®€æ˜“çŸ¥è¯†åº“å®ç°ï¼ˆåŸºäºå‘é‡æ£€ç´¢ï¼‰
    å®é™…ç”Ÿäº§ç¯å¢ƒå¯ä½¿ç”¨ Pineconeã€Milvus ç­‰å‘é‡æ•°æ®åº“
    """
    
    def __init__(self):
        # æ¨¡æ‹Ÿäº§å“çŸ¥è¯†åº“æ•°æ®
        self.documents = [
            {
                "id": "prod_001",
                "category": "product",
                "question": "äº§å“çš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ",
                "answer": "æˆ‘ä»¬çš„æ ‡å‡†ç‰ˆå”®ä»· Â¥299/æœˆï¼Œä¸“ä¸šç‰ˆ Â¥599/æœˆï¼Œä¼ä¸šç‰ˆè¯·è”ç³»æˆ‘ä»¬è·å–æŠ¥ä»·ã€‚",
                "keywords": ["ä»·æ ¼", "è´¹ç”¨", "å¤šå°‘é’±", "æ”¶è´¹"]
            },
            {
                "id": "prod_002",
                "category": "product",
                "question": "æ”¯æŒå“ªäº›æ”¯ä»˜æ–¹å¼ï¼Ÿ",
                "answer": "æˆ‘ä»¬æ”¯æŒæ”¯ä»˜å®ã€å¾®ä¿¡æ”¯ä»˜ã€é“¶è¡Œå¡è½¬è´¦ï¼Œä¼ä¸šç”¨æˆ·è¿˜æ”¯æŒå¯¹å…¬è½¬è´¦ã€‚",
                "keywords": ["æ”¯ä»˜", "ä»˜æ¬¾", "æ”¯ä»˜å®", "å¾®ä¿¡"]
            },
            {
                "id": "serv_001",
                "category": "after_sales",
                "question": "å¦‚ä½•ç”³è¯·é€€æ¬¾ï¼Ÿ",
                "answer": "è´­ä¹°å7å¤©å†…å¯ç”³è¯·æ— ç†ç”±é€€æ¬¾ï¼Œè¯·ç™»å½•è´¦æˆ·åœ¨ã€Œè®¢å•ç®¡ç†ã€ä¸­æäº¤é€€æ¬¾ç”³è¯·ã€‚",
                "keywords": ["é€€æ¬¾", "é€€è´§", "é€€é’±"]
            },
            {
                "id": "serv_002",
                "category": "after_sales",
                "question": "æŠ€æœ¯æ”¯æŒå·¥ä½œæ—¶é—´ï¼Ÿ",
                "answer": "åœ¨çº¿å®¢æœï¼šå·¥ä½œæ—¥ 9:00-21:00ï¼›ç”µè¯æ”¯æŒï¼šå·¥ä½œæ—¥ 9:00-18:00ï¼›ç´§æ€¥é—®é¢˜24å°æ—¶å“åº”ã€‚",
                "keywords": ["å·¥ä½œæ—¶é—´", "å®¢æœæ—¶é—´", "æ”¯æŒæ—¶é—´"]
            }
        ]
        # é¢„è®¡ç®—å…³é”®è¯çš„åµŒå…¥å‘é‡ï¼ˆå®é™…åº”ä½¿ç”¨ Embedding APIï¼‰
        self.keyword_embeddings = self._precompute_embeddings()
    
    def _precompute_embeddings(self) -> Dict:
        """é¢„è®¡ç®—å…³é”®è¯åµŒå…¥ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è°ƒç”¨ Embedding APIï¼‰"""
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„è¯è¢‹æ¨¡å‹ä½œä¸ºç¤ºä¾‹
        embeddings = {}
        for doc in self.documents:
            # å°†å…³é”®è¯è½¬æ¢ä¸ºç®€å•å‘é‡è¡¨ç¤º
            vec = self._simple_embedding(" ".join(doc["keywords"]))
            embeddings[doc["id"]] = vec
        return embeddings
    
    def _simple_embedding(self, text: str) -> np.ndarray:
        """ç®€åŒ–çš„æ–‡æœ¬å‘é‡åŒ–ï¼ˆå®é™…åº”ä½¿ç”¨ text-embedding-ada-002ï¼‰"""
        # åŸºäºå­—ç¬¦é¢‘ç‡çš„ç®€å•ç¼–ç 
        vec = np.zeros(128)
        for i, char in enumerate(text[:128]):
            vec[i] = ord(char) % 100 / 100.0
        return vec
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³çŸ¥è¯†
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›æœ€ç›¸å…³çš„ k æ¡ç»“æœ
        
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°
        """
        query_vec = self._simple_embedding(query)
        
        results = []
        for doc in self.documents:
            doc_vec = self.keyword_embeddings[doc["id"]]
            similarity = cosine_similarity(
                query_vec.reshape(1, -1),
                doc_vec.reshape(1, -1)
            )[0][0]
            
            # å…³é”®è¯åŒ¹é…å¢å¼º
            keyword_match = sum(1 for kw in doc["keywords"] if kw in query)
            final_score = similarity + keyword_match * 0.1
            
            results.append({
                **doc,
                "score": min(final_score, 1.0)  # å½’ä¸€åŒ–åˆ° 0-1
            })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:top_k]


# ==================== æ„å›¾è¯†åˆ«æ¨¡å— ====================

class IntentClassifier:
    """åŸºäºè§„åˆ™å’Œ LLM çš„æ··åˆæ„å›¾è¯†åˆ«"""
    
    # è§„åˆ™æ¨¡å¼å®šä¹‰
    RULE_PATTERNS = {
        IntentType.PRODUCT_INQUIRY: [
            "ä»·æ ¼", "å¤šå°‘é’±", "è´¹ç”¨", "æ€ä¹ˆä¹°", "æœ‰ä»€ä¹ˆåŠŸèƒ½",
            "æ”¯æŒä»€ä¹ˆ", "æ€ä¹ˆç”¨", "æ˜¯ä»€ä¹ˆ"
        ],
        IntentType.AFTER_SALES: [
            "é€€æ¬¾", "é€€è´§", "å”®å", "ç»´ä¿®", "ä¿ä¿®", "æŠ€æœ¯æ”¯æŒ",
            "å®¢æœ", "è”ç³»", "å¸®åŠ©", "é—®é¢˜"
        ],
        IntentType.COMPLAINT: [
            "æŠ•è¯‰", "ä¸¾æŠ¥", "ä¸æ»¡", "å¤ªå·®", "åƒåœ¾", "éª—å­",
            "å‘äºº", "æ¬ºéª—", "è™šå‡å®£ä¼ "
        ],
        IntentType.SMALL_TALK: [
            "ä½ å¥½", "åœ¨å—", "è°¢è°¢", "å†è§", "æ‹œæ‹œ", "å“ˆå“ˆ",
            "æ—©å®‰", "æ™šå®‰", "åƒäº†å—", "å¤©æ°”"
        ]
    }
    
    def classify(self, text: str) -> Tuple[IntentType, float]:
        """
        è¯†åˆ«ç”¨æˆ·æ„å›¾
        
        Args:
            text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        
        Returns:
            (æ„å›¾ç±»å‹, ç½®ä¿¡åº¦)
        """
        text_lower = text.lower()
        scores = {}
        
        # åŸºäºè§„åˆ™çš„åŒ¹é…
        for intent, patterns in self.RULE_PATTERNS.items():
            match_count = sum(1 for p in patterns if p in text_lower)
            scores[intent] = match_count / len(patterns) if patterns else 0
        
        # æ‰¾å‡ºæœ€é«˜åˆ†çš„æ„å›¾
        best_intent = max(scores, key=scores.get)
        confidence = scores[best_intent]
        
        # å¦‚æœè§„åˆ™åŒ¹é…åº¦ä½ï¼Œæ ‡è®°ä¸ºæœªçŸ¥ï¼ˆå¯è¿›ä¸€æ­¥ä½¿ç”¨ LLM åˆ¤æ–­ï¼‰
        if confidence < 0.1:
            return IntentType.UNKNOWN, 0.5
        
        return best_intent, min(confidence * 2, 1.0)  # æ”¾å¤§ç½®ä¿¡åº¦


# ==================== æç¤ºè¯å·¥ç¨‹ ====================

class PromptManager:
    """æç¤ºè¯æ¨¡æ¿ç®¡ç†"""
    
    # ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š

ã€è§’è‰²è®¾å®šã€‘
- å‹å¥½ã€è€å¿ƒã€ä¸“ä¸š
- ä½¿ç”¨ç¤¼è²Œç”¨è¯­
- å›ç­”ç®€æ´æ˜äº†

ã€å›ç­”åŸåˆ™ã€‘
1. ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯å›ç­”
2. å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¦è¯šå‘ŠçŸ¥
3. å¤æ‚é—®é¢˜å»ºè®®è½¬äººå·¥å®¢æœ
4. ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§

ã€æ³¨æ„äº‹é¡¹ã€‘
- ä¸æ¶‰åŠæ”¿æ²»ã€å®—æ•™ç­‰æ•æ„Ÿè¯é¢˜
- ä¸æä¾›åŒ»ç–—ã€æ³•å¾‹ç­‰ä¸“ä¸šå»ºè®®
- ä¿æŠ¤ç”¨æˆ·éšç§ä¿¡æ¯

å½“å‰æ—¶é—´ï¼š{current_time}
ç”¨æˆ·èº«ä»½ï¼š{user_type}
"""
    
    # ä¸Šä¸‹æ–‡æç¤ºè¯
    CONTEXT_PROMPT = """
ã€å¯¹è¯å†å²ã€‘
{conversation_history}

ã€ç›¸å…³çŸ¥è¯†ã€‘
{relevant_knowledge}

ç”¨æˆ·é—®é¢˜ï¼š{user_question}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç»™å‡ºä¸“ä¸šã€å‹å¥½çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·ç¤¼è²Œåœ°å‘ŠçŸ¥éœ€è¦æ›´å¤šä¿¡æ¯æˆ–å»ºè®®è½¬äººå·¥å®¢æœã€‚
"""
    
    @classmethod
    def build_system_prompt(cls, user_type: str = "æ™®é€šç”¨æˆ·") -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return cls.SYSTEM_PROMPT.format(
            current_time=time.strftime("%Y-%m-%d %H:%M"),
            user_type=user_type
        )
    
    @classmethod
    def build_context_prompt(
        cls,
        conversation_history: str,
        relevant_knowledge: str,
        user_question: str
    ) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æç¤ºè¯"""
        return cls.CONTEXT_PROMPT.format(
            conversation_history=conversation_history,
            relevant_knowledge=relevant_knowledge,
            user_question=user_question
        )


# ==================== æ ¸å¿ƒæœåŠ¡ç±» ====================

class CustomerServiceBot:
    """æ™ºèƒ½å®¢æœæœºå™¨äººä¸»ç±»"""
    
    def __init__(self):
        # åˆå§‹åŒ–ç»„ä»¶
        self.knowledge_base = KnowledgeBase()
        self.intent_classifier = IntentClassifier()
        self.contexts: Dict[str, ConversationContext] = {}  # ä¼šè¯ä¸Šä¸‹æ–‡ç¼“å­˜
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        openai.api_key = Config.OPENAI_API_KEY
    
    def get_or_create_context(self, session_id: str) -> ConversationContext:
        """è·å–æˆ–åˆ›å»ºä¼šè¯ä¸Šä¸‹æ–‡"""
        if session_id not in self.contexts:
            self.contexts[session_id] = ConversationContext(
                session_id=session_id,
                messages=[],
                user_profile={}
            )
        return self.contexts[session_id]
    
    def process_message(
        self,
        session_id: str,
        user_message: str
    ) -> Dict:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»å…¥å£
        
        Args:
            session_id: ä¼šè¯å”¯ä¸€æ ‡è¯†
            user_message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        
        Returns:
            åŒ…å«å›å¤å†…å®¹å’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        # 1. è·å–ä¼šè¯ä¸Šä¸‹æ–‡
        context = self.get_or_create_context(session_id)
        
        # 2. æ„å›¾è¯†åˆ«
        intent, confidence = self.intent_classifier.classify(user_message)
        print(f"[æ„å›¾è¯†åˆ«] ç±»å‹: {intent.value}, ç½®ä¿¡åº¦: {confidence:.2f}")
        
        # 3. æ ¹æ®æ„å›¾ç±»å‹å¤„ç†
        if intent == IntentType.COMPLAINT:
            # æŠ•è¯‰ç›´æ¥è½¬äººå·¥
            return self._handle_complaint(context, user_message)
        
        elif intent == IntentType.SMALL_TALK:
            # é—²èŠç®€å•å›å¤
            return self._handle_small_talk(context, user_message)
        
        else:
            # å…¶ä»–æ„å›¾ä½¿ç”¨ RAG + LLM å¤„ç†
            return self._handle_standard_query(
                context, user_message, intent, confidence
            )
    
    def _handle_standard_query(
        self,
        context: ConversationContext,
        user_message: str,
        intent: IntentType,
        confidence: float
    ) -> Dict:
        """å¤„ç†æ ‡å‡†æŸ¥è¯¢ï¼ˆäº§å“å’¨è¯¢ã€å”®åç­‰ï¼‰"""
        
        # 1. æ£€ç´¢çŸ¥è¯†åº“
        relevant_docs = self.knowledge_base.search(user_message, top_k=3)
        
        # 2. åˆ¤æ–­æ˜¯å¦æ‰¾åˆ°ç›¸å…³çŸ¥è¯†
        if not relevant_docs or relevant_docs[0]["score"] < 0.3:
            # çŸ¥è¯†åº“æ— åŒ¹é…ï¼Œéœ€è¦è¿½é—®æˆ–è½¬äººå·¥
            return {
                "reply": "æŠ±æ­‰ï¼Œæˆ‘å¯èƒ½æ²¡æœ‰ç†è§£æ‚¨çš„é—®é¢˜ã€‚æ‚¨èƒ½æ›´è¯¦ç»†åœ°æè¿°ä¸€ä¸‹å—ï¼Ÿæˆ–è€…æ‚¨å¯ä»¥ç›´æ¥è”ç³»äººå·¥å®¢æœè·å–å¸®åŠ©ã€‚",
                "need_clarification": True,
                "transfer_to_human": False,
                "intent": intent.value,
                "confidence": confidence
            }
        
        # 3. æ„å»ºæç¤ºè¯
        knowledge_text = "\n".join([
            f"- {doc['question']}: {doc['answer']}"
            for doc in relevant_docs
        ])
        
        history_text = self._format_history(context.messages[-6:])  # æœ€è¿‘3è½®
        
        # 4. è°ƒç”¨ LLM ç”Ÿæˆå›å¤
        messages = [
            {
                "role": "system",
                "content": PromptManager.build_system_prompt()
            },
            {
                "role": "user",
                "content": PromptManager.build_context_prompt(
                    conversation_history=history_text,
                    relevant_knowledge=knowledge_text,
                    user_question=user_message
                )
            }
        ]
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.MODEL_NAME,
                messages=messages,
                max_tokens=Config.MAX_TOKENS,
                temperature=Config.TEMPERATURE
            )
            
            reply = response.choices[0].message.content
            
            # 5. æ›´æ–°ä¸Šä¸‹æ–‡
            context.add_message("user", user_message)
            context.add_message("assistant", reply)
            
            return {
                "reply": reply,
                "need_clarification": False,
                "transfer_to_human": confidence < 0.5,
                "intent": intent.value,
                "confidence": confidence,
                "sources": [doc["id"] for doc in relevant_docs[:2]]
            }
            
        except Exception as e:
            print(f"[é”™è¯¯] LLM è°ƒç”¨å¤±è´¥: {e}")
            return {
                "reply": "ç³»ç»Ÿæš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "error": str(e),
                "transfer_to_human": True
            }
    
    def _handle_complaint(
        self,
        context: ConversationContext,
        user_message: str
    ) -> Dict:
        """å¤„ç†æŠ•è¯‰ç±»æ¶ˆæ¯"""
        reply = """éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥äº†ä¸å¥½çš„ä½“éªŒï¼æ‚¨çš„åé¦ˆå¯¹æˆ‘ä»¬å¾ˆé‡è¦ã€‚

ä¸ºäº†æ›´å¥½åœ°è§£å†³æ‚¨çš„é—®é¢˜ï¼Œæˆ‘å»ºè®®ï¼š
1. ç›´æ¥è”ç³»äººå·¥å®¢æœï¼š400-XXX-XXXX
2. æˆ–ç•™ä¸‹æ‚¨çš„è”ç³»æ–¹å¼ï¼Œæˆ‘ä»¬ä¼šå°½å¿«ä¸æ‚¨è”ç³»

è¯·é—®æ‚¨æ–¹ä¾¿æä¾›è”ç³»ç”µè¯å—ï¼Ÿ"""
        
        context.add_message("user", user_message)
        context.add_message("assistant", reply)
        
        return {
            "reply": reply,
            "transfer_to_human": True,
            "intent": IntentType.COMPLAINT.value,
            "priority": "high"
        }
    
    def _handle_small_talk(
        self,
        context: ConversationContext,
        user_message: str
    ) -> Dict:
        """å¤„ç†é—²èŠç±»æ¶ˆæ¯"""
        casual_responses = {
            "ä½ å¥½": "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼ŸğŸ˜Š",
            "åœ¨å—": "åœ¨çš„ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ",
            "è°¢è°¢": "ä¸å®¢æ°”ï¼å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ã€‚è¿˜æœ‰å…¶ä»–é—®é¢˜å—ï¼Ÿ",
            "å†è§": "å†è§ï¼ç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ï¼ğŸ‘‹",
            "æ‹œæ‹œ": "æ‹œæ‹œï¼æœŸå¾…å†æ¬¡ä¸ºæ‚¨æœåŠ¡~"
        }
        
        # å°è¯•åŒ¹é…å…³é”®è¯
        reply = None
        for keyword, response in casual_responses.items():
            if keyword in user_message:
                reply = response
                break
        
        if not reply:
            reply = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ"
        
        context.add_message("user", user_message)
        context.add_message("assistant", reply)
        
        return {
            "reply": reply,
            "intent": IntentType.SMALL_TALK.value,
            "casual": True
        }
    
    def _format_history(self, messages: List[Message]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæ–‡æœ¬"""
        lines = []
        for msg in messages:
            role_label = "ç”¨æˆ·" if msg.role == "user" else "åŠ©æ‰‹"
            lines.append(f"{role_label}: {msg.content}")
        return "\n".join(lines)


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

def demo():
    """æ¼”ç¤ºæ™ºèƒ½å®¢æœçš„ä½¿ç”¨"""
    
    print("=" * 60)
    print("ğŸ¤– æ™ºèƒ½å®¢æœæœºå™¨äººæ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–æœºå™¨äºº
    bot = CustomerServiceBot()
    session_id = "demo_session_001"
    
    # æµ‹è¯•å¯¹è¯
    test_messages = [
        "ä½ å¥½",
        "ä½ ä»¬çš„äº§å“ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ",
        "æ”¯æŒæ”¯ä»˜å®ä»˜æ¬¾å—ï¼Ÿ",
        "å¦‚æœä¸æ»¡æ„å¯ä»¥é€€æ¬¾å—ï¼Ÿ",
        "ä½ ä»¬çš„æœåŠ¡å¤ªå·®äº†ï¼Œæˆ‘è¦æŠ•è¯‰ï¼"
    ]
    
    for msg in test_messages:
        print(f"\nğŸ‘¤ ç”¨æˆ·: {msg}")
        print("-" * 40)
        
        result = bot.process_message(session_id, msg)
        
        print(f"ğŸ¤– åŠ©æ‰‹: {result['reply']}")
        print(f"ğŸ“Š æ„å›¾: {result.get('intent', 'unknown')}")
        print(f"ğŸ”¢ ç½®ä¿¡åº¦: {result.get('confidence', 'N/A')}")
        
        if result.get('transfer_to_human'):
            print("âš ï¸  å»ºè®®è½¬äººå·¥å®¢æœ")
        print()


if __name__ == "__main__":
    demo()
```

### ğŸ¯ å…³é”®æ¦‚å¿µè§£é‡Š

| æ¦‚å¿µ | è¯´æ˜ | ä½œç”¨ |
|------|------|------|
| **æ„å›¾è¯†åˆ« (Intent)** | åˆ¤æ–­ç”¨æˆ·æƒ³è¦åšä»€ä¹ˆ | å†³å®šåç»­å¤„ç†æµç¨‹ |
| **RAG** | æ£€ç´¢å¢å¼ºç”Ÿæˆ | è®©å¤§æ¨¡å‹åŸºäºçŸ¥è¯†åº“å›ç­” |
| **ä¸Šä¸‹æ–‡ç®¡ç†** | ä¿å­˜å¤šè½®å¯¹è¯å†å² | ä¿æŒå¯¹è¯è¿è´¯æ€§ |
| **ç½®ä¿¡åº¦** | æ¨¡å‹å¯¹è¯†åˆ«ç»“æœçš„ç¡®å®šç¨‹åº¦ | å†³å®šæ˜¯å¦è½¬äººå·¥ |

### ğŸ“š æ‰©å±•é˜…è¯»

- [ä»€ä¹ˆæ˜¯ RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)](https://arxiv.org/abs/2005.11401)
- [Prompt Engineering æœ€ä½³å®è·µ](https://platform.openai.com/docs/guides/prompt-engineering)
- [å‘é‡æ•°æ®åº“é€‰å‹æŒ‡å—](https://www.pinecone.io/learn/vector-database/)

---

## æ¡ˆä¾‹äºŒï¼šæ–‡æ¡£é—®ç­”ç³»ç»Ÿ

> æŒç»­æ›´æ–°ä¸­...

---

*æœ€åæ›´æ–°: 2025å¹´2æœˆ14æ—¥*
